# Meta-Swadesh List: Comprehensive Criteria and Considerations

## 1. Overview and Purpose

1.  **Definition:** A Swadesh list is a compilation of basic concepts represented by words, intended for lexical comparison across languages or systems.
2.  **Meta-List Purpose:** This document itemizes the criteria, principles, challenges, and applications related to Swadesh lists, acting as a checklist or framework for their creation, evaluation, or adaptation.
3.  **Primary Goal (Standard):** To provide a standardized basis for comparing core vocabularies, primarily for historical linguistics (lexicostatistics, glottochronology).
4.  **Primary Goal (Speculative):** To explore conceptual differences, facilitate world-building, or model distinct cognitive/system perspectives (e.g., CEREBRUM/FORMICA).
5.  **Scope:** This meta-list covers both traditional linguistic and speculative applications.

## 2. Core Principles for Concept Selection (Standard Linguistic Use)

6.  **Universality Criterion (Attempted):** Concepts should ideally exist and be expressible in most, if not all, human languages and cultures.
7.  **Environmental Independence:** Concepts should minimize dependence on specific geographical or ecological environments (e.g., avoiding "ice" if targeting only tropical languages, though broader lists often include it).
8.  **Cultural Independence:** Concepts should minimize dependence on specific cultural practices, technologies, or social structures (e.g., avoiding terms for specific tools or complex kinship roles).
9.  **Lexical Stability:** The words representing the concepts should show relative resistance to borrowing from other languages.
10. **Replacement Rate:** Concepts are chosen whose lexical representations are assumed to have a relatively slow and measurable rate of replacement over time.
11. **Basic Vocabulary Focus:** Concepts should belong to the core, frequently used vocabulary of a language.
12. **Non-Abstractness (Tendency):** Preference often given to concrete concepts (body parts, physical actions) over highly abstract ones, though some abstraction is unavoidable (e.g., "who", "what").
13. **Semantic Primitiveness:** Concepts should be relatively simple and not easily decomposable into other listed concepts.
14. **High Frequency:** Words for these concepts tend to be highly frequent in common discourse.
15. **Early Acquisition:** Concepts are often learned early in language acquisition.
16. **Figurative Language Avoidance:** Concepts whose primary realization is often metaphorical or idiomatic should be avoided.
17. **Synonymy Avoidance:** Concepts prone to having multiple common synonyms within a single language can complicate comparison.
18. **Polysemy Consideration:** Concepts whose words are highly polysemous (multiple meanings) require careful disambiguation.
19. **Ontological Categories:** Aim for a balance across basic ontological categories (objects, actions, properties, relations).
20. **Testability:** The stability and universality of concepts should ideally be empirically testable across language families.

## 3. List Composition and Variations

21. **Standard Lengths:** Common variations include 100-item and 207-item lists.
22. **Rationale for Length:** Shorter lists prioritize stability; longer lists offer more data but may include less stable items.
23. **Historical Development:** Lists have been revised by Swadesh and others (e.g., Swadesh 1950, 1952, 1955, 1971).
24. **Specific Research Adaptations:** Lists may be tailored for specific language families or research questions.
25. **Inclusion/Exclusion Debates:** Specific items on standard lists are subject to ongoing debate regarding their stability or universality (e.g., "cloud", "grease").
26. **Core Subset Identification:** Identifying the absolute most stable subset within a list is a research goal.
27. **Semantic Field Coverage:** Assess how well the list covers fundamental semantic fields (kinship, body, nature, basic actions, etc.).
28. **Part-of-Speech Balance:** Examine the distribution of concepts across parts of speech (nouns, verbs, adjectives, etc.).
29. **Ordering Principles:** Determine if the list order has significance (often arbitrary or loosely grouped).
30. **Exclusion Criteria:** Define explicit reasons for excluding potential concepts (e.g., too specific, too abstract, unstable).

## 4. Data Elicitation and Representation

31. **Elicitation Method:** How are the words corresponding to concepts gathered? (e.g., direct translation, corpus analysis, native speaker consultation).
32. **Translation Accuracy:** Ensuring the elicited word accurately captures the intended concept meaning is critical.
33. **Handling Multiple Translations:** Establish rules for choosing among multiple possible translations for a concept in a language.
34. **Form vs. Meaning:** Prioritize semantic equivalence over formal similarity during elicitation.
35. **Word Form Normalization:** Decide on a standard form (e.g., lemma, infinitive) for representing elicited words.
36. **Phonetic/Phonological Transcription:** Use standardized transcription (e.g., IPA) for accurate representation and comparison.
37. **Morphological Analysis:** Consider whether to include bound morphemes or focus on root forms.
38. **Cognate Identification:** Establish clear criteria for identifying cognates (words with shared ancestry) between languages.
39. **Look-alike vs. Cognate:** Distinguish true cognates from chance resemblances or borrowings.
40. **Borrowing Identification:** Develop methods to detect and potentially exclude loanwords.
41. **Semantic Shift Documentation:** Note instances where the meaning of a word corresponding to a concept has shifted over time.
42. **Data Source Citation:** Properly document the source of lexical data for each language.
43. **Informant Reliability:** Assess the reliability of native speaker informants, if used.
44. **Dialectal Variation:** Account for or normalize dialectal variations within a language.
45. **Language Selection Criteria:** Define the basis for choosing languages for comparison.
46. **Data Formatting:** Standardize the format for storing and presenting the list data.
47. **Metadata Inclusion:** Include relevant metadata (language ISO code, date, source).
48. **Handling Missing Data:** Establish procedures for concepts absent or not easily translated in a language.
49. **Quality Control:** Implement checks for consistency and accuracy in the collected data.
50. **Database Design:** Consider database structures for managing large comparative lists.

## 5. Lexicostatistics and Glottochronology (Standard Applications)

51. **Core Assumption:** Assumes a relatively constant rate of core vocabulary replacement.
52. **Calculating Retention Rate:** Determining the percentage of cognates shared between related languages from the Swadesh list.
53. **Divergence Time Formula:** Applying mathematical formulas (e.g., Swadesh's original formula) to estimate time since divergence based on retention rate.
54. **Calibration:** Calibrating the replacement rate based on languages with known historical divergence points.
55. **Statistical Significance:** Assessing the statistical reliability of calculated divergence times.
56. **Criticism: Constant Rate:** The assumption of a constant replacement rate is heavily criticized as unrealistic.
57. **Criticism: Borrowing Influence:** Undetected borrowing can significantly skew results.
58. **Criticism: Semantic Shift:** Changes in meaning can lead to false cognate identification or rejection.
59. **Criticism: Concept Stability Variation:** Not all concepts on the list have the same replacement rate.
60. **Criticism: Onomatopoeia/Nursery Words:** Certain word types may be prone to independent parallel development.
61. **Alternative Methods:** Comparing Swadesh list results with other phylogenetic methods (e.g., comparative method, computational phylogenetics based on broader data).
62. **Confidence Intervals:** Reporting divergence times with appropriate confidence intervals.
63. **Language Family Trees:** Using results to propose or refine language family trees.
64. **Subgrouping:** Identifying subgroups within larger language families.
65. **Detecting Remote Relationships:** Attempting to find evidence for very deep linguistic relationships.

## 6. Criteria for Speculative / Invented Swadesh Lists (e.g., CEREBRUM/FORMICA)

66. **Thematic Relevance:** Concept translation *must* reflect the core theme/domain (Cognitive Architecture, Collective Intelligence, etc.).
67. **Conceptual Mapping Strategy:** Define how standard concepts are mapped (analogy, metaphor, functional equivalence).
68. **Internal Consistency:** Terms within the invented language should show thematic and (potentially) morphological consistency.
69. **Contrastive Value:** The list should highlight key conceptual differences between the systems being modeled.
70. **Evocative Power:** Terms should be suggestive and contribute to understanding the system's 'worldview'.
71. **System Perspective:** Terms should reflect how the *system* might represent the concept, not just a human label.
72. **Avoiding Anthropomorphism (where applicable):** Ensure terms fit the system's nature (e.g., avoiding human-centric terms for FORMICA unless representing an external observation).
73. **Plausibility within System:** Terms should be plausible given the defined nature of the speculative system.
74. **Explanatory Power:** The invented terms should potentially offer insights into the system's functioning or perspective.
75. **Source Concept Fidelity:** Maintain a clear link back to the original Swadesh concept's meaning, even if the mapping is abstract.
76. **Scalability:** Consider if the term generation strategy can be extended to other concepts.
77. **Disambiguation within Theme:** Ensure terms for related concepts are distinct within the thematic domain.
78. **Level of Abstraction:** Match the level of abstraction in the invented term to the system's nature.
79. **Potential for Formalization:** Consider if terms could map to elements in a formal model (e.g., ontology classes, process labels).
80. **Creative License vs. Rigor:** Balance creative invention with adherence to the defined thematic constraints.

## 7. Annotation Criteria (Extending Beyond Basic Use)

81. **Purpose Definition:** Clearly state the goal of the annotation (e.g., grammatical analysis, semantic typing, thematic tagging, case role mapping).
82. **Annotation Schema Design:** Develop a well-defined set of categories or tags.
83. **Category Granularity:** Decide on the appropriate level of detail for annotation categories.
84. **Ontology Alignment (Optional):** Link annotations to a formal ontology if applicable.
85. **Annotation Guidelines:** Create clear instructions for annotators to ensure consistency.
86. **Inter-Annotator Agreement (IAA):** Measure consistency if multiple annotators are involved.
87. **Handling Ambiguity:** Establish rules for annotating concepts with ambiguous or multiple possible classifications.
88. **Annotation Scope:** Decide whether to annotate the English concept, the target language word, or both.
89. **Annotation Format:** Choose a standard format for storing annotations (e.g., TSV, XML, JSON).
90. **Tooling:** Select or develop tools to facilitate the annotation process.
91. **Case/Type Annotation (CEREBRUM Example):** Classify concepts by functional role (Noun-Entity, Verb-Action, Adjective-Property, Pronoun, Quantifier, Relation, Location, Time, Manner, etc.).
92. **Thematic Annotation:** Tag concepts based on their relevance to specific project themes.
93. **Stability Annotation:** Annotate concepts with estimated lexical stability scores (if available).
94. **Universality Annotation:** Annotate concepts based on evidence for their cross-linguistic universality.
95. **Annotation Validation:** Implement procedures to check the quality and correctness of annotations.

## 8. Methodological Considerations for List Generation/Adaptation

96. **Source List Selection:** Justify the choice of the base Swadesh list (e.g., 100 vs. 207 items).
97. **Translation/Mapping Strategy Documentation:** Clearly document the methods used (e.g., expert consultation, corpus analysis, computational methods, thematic analogy).
98. **Team Expertise:** Ensure the team possesses necessary expertise (linguistics, domain knowledge for speculative lists).
99. **Pilot Study:** Conduct a pilot study on a subset of concepts or languages.
100. **Iterative Refinement:** Plan for iterative review and refinement of the list and translations/mappings.
101. **Version Control:** Use version control systems to track changes to the list and associated data.
102. **Reproducibility:** Document the process thoroughly to ensure reproducibility.
103. **Bias Awareness:** Be mindful of potential biases in concept selection or translation (e.g., Eurocentrism in older lists).
104. **Ethical Considerations (Human Languages):** Ensure proper attribution, respect for cultural context, and data privacy if working with endangered or indigenous languages.
105. **Computational Tools:** Utilize computational tools for data management, comparison, and analysis where appropriate.
106. **Peer Review:** Subject the list and methodology to peer review if intended for academic use.
107. **Documentation Standards:** Adhere to clear documentation standards for the list and its creation process.
108. **Target Audience:** Consider the intended audience when deciding on the level of detail and presentation format.
109. **Resource Allocation:** Estimate the time and resources required for list creation or adaptation.
110. **Fallback Strategy:** Define how to handle concepts that prove exceptionally difficult to translate or map.

## 9. Challenges and Criticisms

111. **Concept Universality Debate:** The true universality of many concepts is questionable.
112. **Semantic Equivalence Problem:** Achieving perfect semantic equivalence across languages is difficult, if not impossible.
113. **Lexical Stability Variation:** Replacement rates vary significantly between concepts and language families.
114. **Borrowing Detection Difficulty:** Identifying subtle or ancient borrowings can be challenging.
115. **Influence of Taboo:** Word avoidance due to taboo can accelerate replacement rates.
116. **Onomatopoeia/Sound Symbolism:** These can lead to non-historical similarities.
117. **Morphological Complexity:** Comparing languages with vastly different morphological structures is complex.
118. **Proto-Language Reconstruction Limits:** Swadesh lists alone are insufficient for full proto-language reconstruction.
119. **Glottochronology Accuracy:** The accuracy and theoretical basis of glottochronology remain highly controversial.
120. **Sampling Bias:** The selection of languages can influence observed stability rates.
121. **Data Quality Issues:** Errors in elicitation or transcription can invalidate results.
122. **Subjectivity in Cognate Judgment:** Determining cognates can involve subjective decisions.
123. **Influence of Areal Features:** Shared features due to language contact can confound historical signals.
124. **Limited Scope:** Core vocabulary represents only a small fraction of a language's lexicon.
125. **Oversimplification:** Critics argue the method oversimplifies complex language change processes.

## 10. Applications Beyond Historical Linguistics

126. **Second Language Acquisition:** Core vocabulary lists can guide curriculum development.
127. **Artificial Language Creation (Conlangs):** Used as a basis for developing core vocabulary in constructed languages.
128. **Speculative Biology/Cognition (e.g., CEREBRUM):** Exploring how non-human or artificial systems might conceptualize basic ideas.
129. **Conceptual Modeling:** Highlighting fundamental concepts in a domain.
130. **Cross-Cultural Comparison:** Examining how basic concepts are lexicalized across different cultures (with caveats).
131. **Natural Language Processing (NLP):** Potentially useful for tasks involving basic semantics or cross-lingual alignment.
132. **Cognitive Science:** Investigating the structure of basic conceptual categories.
133. **Anthropology:** Studying cultural perspectives embedded in core vocabulary.
134. **Educational Tool:** Teaching basic linguistic concepts and diversity.
135. **World-Building (Fiction/Games):** Providing a structured way to develop distinct linguistic flavors for fictional cultures.

## 11. Data Management and Format Considerations

136. **Unique Identifiers:** Assign stable unique IDs to each concept.
137. **Structured Data Format:** Use formats like CSV, TSV, JSON, XML, or relational databases.
138. **Character Encoding:** Use UTF-8 consistently.
139. **Metadata Standards:** Define required metadata fields (language, source, date, annotator).
140. **Linking Data:** Establish methods for linking list data to other linguistic resources (e.g., lexicons, corpora).
141. **Backup and Archiving:** Implement robust data backup procedures.
142. **Accessibility:** Consider open data principles if appropriate.
143. **Interoperability:** Design data formats to be interoperable with common linguistic software tools.
144. **Scalability:** Ensure the data management approach can handle increasing numbers of languages or concepts.
145. **Queryability:** Data should be easily queryable for specific concepts, languages, or annotations.

## 12. Evaluation Criteria for Swadesh Lists

146. **Clarity of Purpose:** Is the goal of the list clearly defined?
147. **Justification of Concept Selection:** Are the criteria for including/excluding concepts explicit and well-justified?
148. **Methodological Transparency:** Is the process of data elicitation and representation clearly documented?
149. **Data Accuracy:** How reliable and accurate is the lexical data presented?
150. **Annotation Quality (if applicable):** Are annotations well-defined, consistent, and useful?
151. **Internal Consistency:** Does the list adhere to its own stated principles?
152. **Coverage:** How well does the list cover the intended conceptual space?
153. **Comparability:** How effectively does the list facilitate comparison across its target languages/systems?
154. **Fitness for Purpose:** How well does the list achieve its stated goals (linguistic, speculative, etc.)?
155. **Acknowledged Limitations:** Does the documentation acknowledge the inherent limitations and criticisms of the approach?

## 13. Additional Considerations for CEREBRUM/FORMICA Context

156. **Mapping to CEREBRUM Cases:** How do Swadesh concepts relate to the slots/roles in CEREBRUM's case representations?
157. **Representing FORMICA's Collective Logic:** How can Swadesh concepts be mapped to pheromone trails, nest structure, colony roles, etc.?
158. **Level of Granularity:** Does the Swadesh list operate at the right level of detail for modeling these systems?
159. **Dynamic Concepts:** How to handle concepts that might be dynamic or context-dependent in these systems (e.g., 'we' in a shifting colony)?
160. **Sensory Modalities:** Emphasize relevant modalities (e.g., chemoreception for FORMICA, abstract data for CEREBRUM).
161. **Action Primitives:** Map basic verbs (eat, walk, fly) to corresponding action primitives in the modeled systems.
162. **Relational Concepts:** Focus on how relational terms (in, at, with) translate to spatial, logical, or social relations.
163. **Quantifiers:** How do the systems represent quantity (precise counts vs. estimates, swarm size).
164. **Qualifiers/Properties:** Map adjectives (big, small, hot, cold) to relevant sensory or state parameters.
165. **Social Concepts:** Pay special attention to pronouns and kinship terms, mapping them to agent identification and social structure (Ego-Node, Kin-Self, Collective-Graph).
166. **Temporal Concepts:** Map 'when', 'day', 'night' to internal clocks, cycles, or event timestamps.
167. **Logical Operators:** Ensure 'not', 'and', 'if' map to core logical operations within CEREBRUM.
168. **Metaphorical Consistency:** Ensure the metaphors used in mapping are applied consistently.
169. **Potential for Simulation:** Can the mapped concepts be used as inputs or outputs in a simulation of CEREBRUM or FORMICA?
170. **Generative Potential:** Could the mapping principles be used to generate plausible terms for concepts *not* on the Swadesh list?

## 14. Further Potential Criteria & Concepts (Reaching ~200)

171. **Concept Frequency Analysis:** Evaluate concepts based on cross-linguistic frequency data.
172. **Concept Imageability:** Assess concepts based on how easily they evoke a mental image.
173. **Concept Concreteness:** Rate concepts on a concrete-abstract scale.
174. **Inter-Concept Semantic Distance:** Measure the semantic relatedness between concepts on the list.
175. **Historical Layering:** Identify potential historical layers within the core vocabulary.
176. **Language Acquisition Order:** Correlate concepts with typical order of acquisition in children.
177. **Aphasia Studies Relevance:** Examine how core concepts are affected in language disorders.
178. **Lexical Typology:** Relate concept representation to broader lexical typological patterns.
179. **Computational Tractability:** Assess how easily concepts can be handled by NLP algorithms.
180. **Cultural Salience:** Evaluate the prominence of concepts within specific cultural contexts.
181. **Polysemy Network Analysis:** Map the different senses associated with words for core concepts.
182. **Figurative Extension Analysis:** Study common metaphorical extensions of core concept words.
183. **Concept Embodiment:** Relate concepts to embodied cognition theories.
184. **Sensory Domain Mapping:** Classify concepts by primary sensory domain (visual, auditory, tactile).
185. **Emotional Valence:** Annotate concepts with typical emotional associations.
186. **Grammatical Function Potential:** Analyze the typical grammatical functions associated with each concept.
187. **Semantic Role Labeling:** Connect concepts to standard semantic roles (Agent, Patient, Instrument).
188. **Cross-Modal Mapping:** Investigate links between linguistic concepts and non-linguistic representations.
189. **Concept Definition Complexity:** Assess the complexity required to define each concept.
190. **Ambiguity Resolution Strategies:** Document typical ways languages disambiguate polysemous core words.
191. **Stability Index Refinement:** Develop more nuanced measures of lexical stability.
192. **Network Analysis of Lexicon:** Position Swadesh concepts within a larger network model of the lexicon.
193. **Diachronic Semantic Change Paths:** Map typical historical pathways of meaning change for core concepts.
194. **Cognitive Load Assessment:** Evaluate the cognitive effort required to process/learn each concept.
195. **Cross-Cultural Variation in Mapping:** Document differences in how cultures map words to the 'same' concept.
196. **Integration with Ontologies:** Align Swadesh concepts with upper-level ontologies (e.g., SUMO, BFO).
197. **Use in Machine Translation:** Assess the role of core vocabulary in MT systems.
198. **Concept Prerequisite Analysis:** Determine which concepts might be prerequisite for understanding others.
199. **Teaching/Learning Difficulty:** Rate concepts by their typical difficulty for language learners.
200. **Future Research Directions:** Identify open questions and areas for future work related to Swadesh lists.
201. **Conceptual Density:** Evaluate semantic fields for density of concepts.
202. **Lexical Gaps Analysis:** Identify common lexical gaps related to Swadesh concepts across languages.
203. **Etymological Transparency:** Assess whether words for concepts are typically morphologically simple or complex.
204. **Register Variation:** Analyze how words for core concepts vary across formal/informal registers.
205. **Comparison with other Core Lists:** Contrast with other basic vocabulary lists (e.g., Dolgopolsky list).
206. **Automatability of Analysis:** Evaluate how much of the Swadesh list creation/analysis process can be automated.
207. **Visualization Techniques:** Explore methods for visualizing comparative Swadesh list data.


## 15. See Also

*   [`swadesh_list.md`](./swadesh_list.md): The speculative Swadesh list for CEREBRUM and FORMICA, generated according to relevant criteria above.
*   External resources on Swadesh lists, lexicostatistics, and glottochronology. 
## Case Functions in Cognitive Model Systems

**Table 1: Case Functions in Cognitive Model Systems**

| Abbr | Case | Function in CEREBRUM | Example Usage |
|------|------|----------------------|---------------|
| **[NOM]** | **Nominative** | Model as active agent; acts as the primary producer of predictions and exerts causal influence on other models | Model X [NOM] generates predictions about data distributions; controls downstream processing |
| **[ACC]** | **Accusative** | Model as object of process; receives transformations and updates from other models or processes | Process applies to Model X [ACC]; optimization procedures refine Model X's parameters |
| **[GEN]** | **Genitive** | Model as source/possessor; functions as the origin of outputs, products, and derived models | Output of Model X [GEN]; intelligence products derived from Model X's inferences |
| **[DAT]** | **Dative** | Model as recipient; specifically configured to receive and process incoming data flows | Data fed into Model X [DAT]; Model X receives information from external sources |
| **[INS]** | **Instrumental** | Model as method/tool; serves as the means by which analytical operations are performed | Analysis performed via Model X [INS]; Model X implements analytical procedures |
| **[LOC]** | **Locative** | Model as context; provides environmental constraints and situational parameters | Parameters within Model X [LOC]; environmental contingencies modeled by X |
| **[ABL]** | **Ablative** | Model as origin/cause; represents historical conditions or causal precursors | Insights derived from Model X [ABL]; causal attributions traced to Model X |
| **[VOC]** | **Vocative** | Model as addressable entity; functions as a directly callable interface with name-based activation | "Hey Model X" [VOC]; direct invocation of Model X for task initialization; documentation reference point |

Within intelligence production systems, these case relationships serve critical functional roles: nominative models act as primary analytical engines driving the intelligence case; accusative models become targets of quality assessment and improvement; multimodal generitive models generate documentation and reports; dative models receive and process collected intelligence data; instrumental models provide the methodological framework for investigations; locative models establish situational boundaries; ablative models represent the historical origins of analytical conclusions; and vocative models serve as directly addressable interfaces for command initiation and documentation reference. Together, these case relationships create a comprehensive framework for structured intelligence workflows.
@fig:fig4 illustrates how this core framework integrates with intelligence case management.

![Generative Model Integration in Intelligence Case Management.](Figure_4.png){#fig:fig4}

## A Preliminary Example of a Case-Bearing Model: Homeostatic Thermostat
Consider a cognitive model of a homeostatic thermostat that perceives room temperature with a thermometer, and regulates temperature through connected heating and cooling systems. In nominative case [NOM], the thermostat model actively generates temperature predictions and dispatches control signals, functioning as the primary agent in the temperature regulation process. When placed in accusative case [ACC], this same model becomes the object of optimization processes, with its parameters being updated based on prediction errors between expected and actual temperature readings. In dative case [DAT], the thermostat model receives environmental temperature data streams and occupant comfort preferences as inputs. The genitive case [GEN] transforms the model into a generator of temperature regulation reports and system performance analytics ("genitive AI"). When in instrumental case [INS], the thermostat serves as a computational tool implementing control algorithms for other systems requiring temperature management. The locative case [LOC] reconfigures the model to represent the contextual environment in which temperature regulation occurs, modeling building thermal properties, or discussing something within the model as a location. Finally, in ablative case [ABL], the thermostat functions as the origin of historical temperature data and control decisions, providing causal explanations for current thermal conditions. This single cognitive model thus assumes dramatically different functional roles while maintaining its core identity as a thermostat.

## Declinability of Active Inference Generative Models
At the core of CEREBRUM lies the concept of **declinability** - the capacity for generative models to assume different morphological and functional roles through case transformations, mirroring the declension patterns of nouns in morphologically rich languages. Unlike traditional approaches where models maintain fixed roles, or variable roles defined by analytical pipelines, CEREBRUM treats cognitive models as flexible entities capable of morphological adaptation to different operational contexts.

## Morphological Transformation of Generative Models
When an active inference generative model undergoes case transformation, it experiences orchestrated systematic changes such as:
1. **Functional Interfaces**: Input/output specifications change to match the case role requirements
2. **Parameter Access Patterns**: Which parameters are exposed or constrained changes based on case
3. **Prior Distributions**: Different cases employ different prior constraints on parameter values
4. **Update Dynamics**: The ways in which the model updates its internal states vary by case role
5. **Computational Resources**: Different cases receive different precision-weighted computational allocations

These changes are summarized in Table 2:

**Table 2: Transformational Properties of Active Inference Generative Models Under Case Declensions**

| Case | Parametric Changes | Interface Transformations | Precision Weighting |
|------|-------------------|--------------------------|-------------------|
| **[NOM]** | Fully accessible parameters; all degrees of freedom available for prediction generation; strongest prior constraints on likelihood mapping | Outputs predictions; exposes forward inference pathways; prediction interfaces activated | Highest precision on likelihood; maximizes precision of generative mapping from internal states to observations |
| **[ACC]** | Restricted parameter access; plasticity gates opened; learning rate parameters prioritized | Receives transformations; update interfaces exposed; gradient reception pathways active | Highest precision on parameters; maximizes precision of parameter updates based on prediction errors |
| **[DAT]** | Input-focused parameterization; sensory mapping parameters prioritized; perceptual categorization parameters activated | Receives data flows; input processing interfaces exposed; sensory reception channels active | Highest precision on inputs; maximizes precision of incoming data relative to internal expectations |
| **[GEN]** | "Genitive AI"; Output-focused parameterization; production parameters activated; generative pathway emphasis | Generates products; output interfaces prioritized; production pathways activated | Highest precision on outputs; maximizes precision of generated products relative to internal models |
| **[INS]** | Method-oriented parameters exposed; algorithmic parameters accessible; procedural knowledge emphasized | Implements processes; computational interfaces active; procedural execution pathways open | Highest precision on operations; maximizes precision of procedural execution relative to methodological expectations |
| **[LOC]** | Context parameters emphasized; environmental modeling parameters prioritized; situational knowledge emphasized | Provides environmental constraints; contextual interfaces active; environmental modeling pathways prioritized | Highest precision on contexts; maximizes precision of contextual representation relative to environmental dynamics |
| **[ABL]** | Origin states emphasized; historical parameters accessible; causal attribution pathways strengthened | Source of information; historical data interfaces active; causal explanation pathways open | Highest precision on historical data; maximizes precision of causal attributions and historical reconstructions |
| **[VOC]** | Identity parameters prioritized; naming and identification parameters activated; interface exposure emphasized | Maintains addressable interfaces; name recognition pathways activated; command reception channels open | Highest precision on identification cues; maximizes precision of name recognition relative to calling patterns |

## Active Inference Model Declension
Consider a perception-oriented generative model M with parameters theta, internal states s, and observational distribution p(o|s,theta). When declined across cases, this single model transforms as follows:
- **M[NOM]**: Actively generates predictions by sampling from p(o|s,theta), with all parameters fully accessible
- **M[ACC]**: Becomes the target of updates, with parameter gradients calculated from prediction errors
- **M[DAT]**: Configured to receive data flows, with specific input interfaces activated
- **M[GEN]**: Optimized to generate outputs, with output interfaces prioritized
- **M[INS]**: Functions as a computational method, exposing algorithmic interfaces
- **M[LOC]**: Provides contextual constraints for other models, with environmental parameters exposed
- **M[ABL]**: Serves as an information source, with historical data accessible
- **M[VOC]**: Functions as an addressable entity responding to direct invocation, with naming parameters activated
The Vocative case [VOC] represents a unique functional role where models serve as directly addressable entities within a model ecosystem. Unlike other cases that focus on data processing or transformational aspects, the vocative case specifically optimizes a model for name-based recognition and command reception. This has particular relevance in synthetic intelligence environments where models must be selectively activated or "woken up" through explicit address, similar to how humans are called by name to gain their attention. The vocative case maintains specialized interfaces for handling direct commands, documentation references, and initialization requests. In practical applications, models in vocative case might serve as conversational agents awaiting activation, documentation reference points within technical specifications, or system components that remain dormant until explicitly addressed. This pattern mimics the linguistic vocative case where a noun is used in direct address, as in "Hey Siri" or "OK Google" activation phrases for digital assistants, creating a natural bridging pattern between human language interaction and model orchestration.

This systematic pattern of transformations constitutes a complete "declension paradigm" for cognitive models, using precision-modulation to fulfill diverse functional roles while maintaining their core identity.

A sequence diagram illustrating the workflow of case transformations is shown in @fig:fig5.

![Model Workflows as Case Transformations - Sequence Diagram.](Figure_5.png){#fig:fig5}